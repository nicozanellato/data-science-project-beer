{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from getpass import getpass\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "from random import randint\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/59.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://untappd.com/brewery/top_rated?country_id=130\",headers = headers)\n",
    "url= \"https://untappd.com/brewery/top_rated?country_id=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all <options> in a list\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "options = soup.find_all(\"option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each element in that list, pull out the \"value\" attribute\n",
    "values = [o.get(\"value\") for o in options]\n",
    "del values[:8] #delete first row 'all' from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for row in values:\n",
    "        time.sleep(randint(5,10)) # wait between 5 to 10 seconds, not to hammer the servers with requests\n",
    "        page1 = requests.get(url+str(row) ,  headers = headers)\n",
    "        soup1 = BeautifulSoup(page1.content, 'html.parser')\n",
    "        sf=soup1.find('p', class_='no-activity')\n",
    "        \n",
    "        if sf: #if you find the class no-activity, it means that the page is empty\n",
    "            print(row,\"No breweries listed\")\n",
    "            \n",
    "        else:\n",
    "            print(row,\"printing... hopefully!\")\n",
    "            all_names=[] #all brewery names in a list\n",
    "            names = soup1.find_all(\"p\",  class_=\"name\")\n",
    "            for p in names: \n",
    "                names2 = p.text #cycle through names and drop all tags etc.\n",
    "                all_names.append(names2) #add this new text only value to 'allnames'\n",
    "            \n",
    "            all_country=[]   #getting the country name for the list of breweries\n",
    "            country = soup1.find_all(\"p\",  class_=\"style\")\n",
    "            for p in country: \n",
    "                country2 = p.text #cycle through names and drop all tags etc.\n",
    "                all_country.append(country2) #add this new text only value to 'allnames'\n",
    "                \n",
    "            all_nbeers=[]#number of beers listed\n",
    "            nbeers = soup1.find_all(\"p\",  class_=\"abv\")\n",
    "            for p in nbeers: \n",
    "                nbeers2 = p.text.replace('Beers','') #cycle through names and drop all \"Beers\"\n",
    "                all_nbeers.append(nbeers2) #add this new text only value to 'allnames'\n",
    "                \n",
    "            all_nreviews=[] #number of reviewers\n",
    "            nreviews = soup1.find_all(\"p\",  class_=\"ibu\")\n",
    "            for p in nreviews: \n",
    "                nreviews2 = p.text.replace('Ratings','') #cycle through names and drop all tags etc.\n",
    "                all_nreviews.append(nreviews2) #add this new text only value to 'allnames'\n",
    "                \n",
    "            all_rating=[]\n",
    "            rating = soup1.find_all(\"p\",  class_=\"rating\")\n",
    "            for p in rating: \n",
    "                rating2 = p.text.replace('(','').replace(')','') #cycle through names and drop all ( )\n",
    "                all_rating.append(rating2) #add this new text only value to 'allnames'\n",
    "                \n",
    "            all_locations=[]\n",
    "            all_styles=[]\n",
    "            all_links=[] # list of links in order to get location we need to get into that webpage\n",
    "            img_links=[] # list of images links\n",
    "            \n",
    "            prova=soup1.find_all('a', class_='label', href=True)\n",
    "            img=soup1.find_all('img',src=True)\n",
    "            #get all images url\n",
    "            for image in img:\n",
    "            \n",
    "                img_links.append(image['src'])\n",
    "            \n",
    "            img_links= img_links[:len(img_links)-20] #delete last 20 rows from images list because they contain non related pics\n",
    "            # get all info from beers page\n",
    "            for p in prova: \n",
    "                time.sleep(randint(6,10))  \n",
    "                all_links.append('https://untappd.com'+p['href'])\n",
    "                \n",
    "                brewery_detail = requests.get('https://untappd.com'+p['href']+'/beer', headers = headers)\n",
    "                soup3=BeautifulSoup(brewery_detail.content, 'html.parser')\n",
    "                \n",
    "                try:\n",
    "                    location=soup3.find('p', class_='brewery').text\n",
    "                \n",
    "                    all_locations.append(location) #append location as written on the website\n",
    "\n",
    "                    style=soup3.find('p', class_='style').text\n",
    "                    all_styles.append(style) #brewery style as on the website \n",
    "                    \n",
    "                    #get beer id    \n",
    "                    beer_id = [d.get(\"data-bid\") for d in soup3.find_all(\"div\", {\"class\": \"beer-item\"})]\n",
    "\n",
    "                    #get beer names\n",
    "                    beers_name=soup3.find_all('p', class_='name')\n",
    "                    br_beers_name = [] #create empty list\n",
    "\n",
    "                    for p in beers_name: \n",
    "                        beers_names2 = p.text #cycle through names and drop all tags etc.\n",
    "                        br_beers_name.append(beers_names2)#add this new text only value to 'allnames'\n",
    "\n",
    "                    #get full description going through each beer id\n",
    "\n",
    "                    beer_description=[]\n",
    "\n",
    "                    for d in beer_id:\n",
    "                        b_descr=soup3.find('p', class_='desc desc-full-'+str(d))\n",
    "                        beer_description.append(b_descr.text)\n",
    "\n",
    "                    #get brewery name and repeat it for the number of beers listed\n",
    "                    brewery_n=soup3.find('h1').text\n",
    "                    brewery_name=[]\n",
    "                    brewery_name=np.repeat(brewery_n,len(beer_id))\n",
    "\n",
    "                    beer_style = [] #create empty list for beer style\n",
    "                    b_style=soup3.find_all('p', class_='style')\n",
    "\n",
    "                    for p in b_style: \n",
    "                        b_style2 = p.text #cycle through names and drop all tags etc.\n",
    "                        beer_style.append(b_style2)#add this new text only value to 'allnames'\n",
    "\n",
    "                    del beer_style[0] #delete first entry as it is the style of the brewery not the beer\n",
    "\n",
    "                        #get beers ABV\n",
    "                    ABVs=[]\n",
    "\n",
    "                    b_abv=soup3.find_all('p',class_='abv')\n",
    "\n",
    "                    for p in b_abv:\n",
    "                        b_abv=p.text.replace('%','').replace('ABV','')\n",
    "                        #float(b_abv)\n",
    "                        ABVs.append(b_abv)\n",
    "\n",
    "                    #get beers International Bitterness Unit\n",
    "                    IBUs=[]\n",
    "                    b_ibu=soup3.find_all('p',class_='ibu')\n",
    "\n",
    "                    for p in b_ibu:\n",
    "                        b_ibu=p.text.replace('IBU','')\n",
    "                        IBUs.append(b_ibu)\n",
    "\n",
    "                    #ratings\n",
    "                    b_ratings=[]\n",
    "\n",
    "                    b_r=soup3.find_all('p', class_='rating')\n",
    "\n",
    "                    for p in b_r:\n",
    "                        b_r=p.text.replace('(','').replace(')','')\n",
    "                        b_ratings.append(b_r)\n",
    "\n",
    "                    del b_ratings[0] #this is the rating of the brewery \n",
    "\n",
    "                    #raters\n",
    "                    b_raters=[]\n",
    "\n",
    "                    b_rtrs=soup3.find_all('p', class_='raters')\n",
    "\n",
    "                    for p in b_rtrs:\n",
    "                        b_rtrs=p.text.replace('Ratings','')\n",
    "                        b_raters.append(b_rtrs)\n",
    "\n",
    "                    del b_raters[0] #this is the raters of the brewery \n",
    "\n",
    "                    #date added\n",
    "                    date_added=[]\n",
    "\n",
    "                    date=soup3.find_all('p', class_='date')\n",
    "\n",
    "                    for p in date:\n",
    "                        date=p.text.replace('Added','')\n",
    "                        date_added.append(date)\n",
    "\n",
    "                    del date_added[0] #this is the date the brewery was added\n",
    "\n",
    "                    df2 = pd.DataFrame(np.column_stack([beer_id,brewery_name,br_beers_name, beer_style, beer_description, ABVs, IBUs, b_raters, b_ratings, date_added]), \n",
    "                          columns=['Beer ID','Brewery', 'Beer name', 'Beer Style', 'Beer Description', 'ABV', 'IBU', 'No Raters', 'Rating', 'Date Added'])\n",
    "\n",
    "                    df2.to_csv('All Beers.csv',mode='a', header=False, encoding='utf-8')\n",
    "                except AttributeError:\n",
    "                    all_locations.append(\"NA\")\n",
    "                    all_styles.append(\"NA\") \n",
    "                    continue\n",
    "   ################################         \n",
    "            \n",
    "            \n",
    "            #create a table using the formatted lists from beautifulsoup delimited with commas\n",
    "            table = {'Brewery': [all_names], 'Country': [all_country], 'No. Beers': [all_nbeers], 'No. Reviews': [all_nreviews], 'Rating': [all_rating],\n",
    "                    'Untappd URL': [all_links], 'Image URL': [img_links], 'Style': [all_styles], 'Location': [all_locations] }\n",
    "            #print(table)\n",
    "            #create and populate a pandas dataframe from the table using numpy\n",
    "            df1 = pd.DataFrame(np.column_stack([all_names, all_country, all_nbeers, all_nreviews, all_rating, all_links, img_links, all_styles, all_locations]), \n",
    "                  columns=['Brewery', 'Country', 'No. Beers', 'No. Reviews', 'Rating','Untappd URL','Image URL', 'Style', 'Location'])\n",
    "        \n",
    "\n",
    "            df1.to_csv('Breweries.csv', mode='a', header=False, encoding='utf-8') #keep appending onto csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps_key = googlemaps.Client(key = 'YOUR PERSONAL KEY')\n",
    "\n",
    "df1[\"Lat\"] = None\n",
    "df1[\"Lon\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df1.index:\n",
    "    time.sleep(1)\n",
    "    geocode_result = gmaps_key.geocode(df1.iat[i,9])\n",
    "    try:\n",
    "        lat=geocode_result[0][\"geometry\"][\"location\"][\"lat\"]\n",
    "        lon=geocode_result[0][\"geometry\"][\"location\"][\"lng\"]\n",
    "        df1.at[i, \"Lat\"] = lat \n",
    "        df1.at[i, \"Lon\"] = lon\n",
    "    except:\n",
    "        lat = None\n",
    "        lon = None\n",
    "\n",
    "geocode_result = gmaps_key.geocode(df.iat[0,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=geocode_result[0][\"geometry\"][\"location\"][\"lat\"]\n",
    "lon=geocode_result[0][\"geometry\"][\"location\"][\"lng\"]\n",
    "df.iat[0, df.columns.get_loc(\"Lat\")] = lat\n",
    "df.iat[0, df.columns.get_loc(\"Lon\")] = lon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
